{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import os\n",
    "from functools import cmp_to_key\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from deepctr.inputs import SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names\n",
    "from deepctr.models import DeepFM\n",
    "import pickle\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_from_file(file, type='default', skiprow = 0):\n",
    "    data = list()\n",
    "    size = 0\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            size += 1\n",
    "            try:\n",
    "                if size <= skiprow:\n",
    "                    continue\n",
    "                line = line.replace('\"', '').strip()\n",
    "                if len(line) <= 0:\n",
    "                    continue\n",
    "                if type == 'interet':\n",
    "                    parts = line.split(\",\")\n",
    "                    name = parts[0]\n",
    "                    size = int(parts[1])\n",
    "                    if size > 10 and len(name) > 0:\n",
    "                        data.append(name)\n",
    "                elif type == 'loc':\n",
    "                    parts = line.split(\",\")\n",
    "                    province = parts[0]\n",
    "                    city = parts[1]\n",
    "                    area = parts[2]\n",
    "                    data.append(province)\n",
    "                    data.append(province + \"_\" + city)\n",
    "                    data.append(province + \"_\" + city + \"_\" + area)\n",
    "                elif type == 'publisher':\n",
    "                    parts = line.split(\",\")\n",
    "                    name = parts[0]\n",
    "                    size = int(parts[1])\n",
    "                    if size > 10:\n",
    "                        data.append(name)\n",
    "                else:\n",
    "                    data.append(line)\n",
    "            except:\n",
    "                print(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(dir, type='default', skiprow = 0):\n",
    "    data = list()\n",
    "    size = 0\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "        data+=load_dict_from_file(dir + \"/\" + file, type, skiprow)\n",
    "    return list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe_file = 'lbe.pickle'\n",
    "data_map_file = 'data_map.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle_data(file, data):\n",
    "    f = open(file, 'wb')\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def load_pickle_data(file):\n",
    "    try:\n",
    "        f1 = open(file, 'rb')\n",
    "        return pickle.load(f1)\n",
    "    except:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky game\n",
      "中国新闻网,绥芬河政府网站,1\n",
      "Ansun Biopharma, Inc.,1\n"
     ]
    }
   ],
   "source": [
    "its = load_dict('/home/recsys/dataset/dict/interets', 'interet')\n",
    "locs = load_dict('/home/recsys/dataset/dict/loc', 'loc')\n",
    "publishers = load_dict('/home/recsys/dataset/dict/publisher', 'publisher', 1)\n",
    "cates = load_dict_from_file('/home/recsys/dataset/dict/cate.csv', 'cate', 1)\n",
    "channels = load_dict_from_file('/home/recsys/dataset/dict/channel.csv', 'channel', 1)\n",
    "publishers.append('other')\n",
    "channels.append('')\n",
    "\n",
    "u_levels = [str(i) for i in range(0, 10)]\n",
    "media_levels = [str(i) for i in range(0, 10)]\n",
    "rschannles = [str(i) for i in range(1, 33)]\n",
    "vocabs = dict()\n",
    "vocabs['u_level'] = u_levels\n",
    "vocabs['t_channel'] = channels\n",
    "vocabs['cp_l1_category'] = cates\n",
    "vocabs['cp_publisher'] = publishers\n",
    "vocabs['cp_media_level'] = media_levels\n",
    "vocabs['rschannles'] = rschannles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_path):\n",
    "    files = os.listdir(dir_path)\n",
    "    print(dir_path)\n",
    "    dataset = tf.data.TFRecordDataset(filenames = [dir_path + '/' + file for file in files], num_parallel_reads= tf.data.experimental.AUTOTUNE )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data set\n",
    "def print_dataset(data_set):\n",
    "        iterator = data_set.make_one_shot_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "        num_batch = 0\n",
    "        with tf.train.MonitoredTrainingSession() as sess:\n",
    "            while not sess.should_stop():\n",
    "                value = sess.run(next_element)\n",
    "                num_batch += 1\n",
    "                print(\"Num Batch: \", num_batch)\n",
    "                print(\"Batch value: \", value)\n",
    "                \n",
    "def print_dataset2(data_set):\n",
    "        iterator = data_set.make_initializable_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "        num_batch = 0\n",
    "        with tf.train.MonitoredTrainingSession() as sess:\n",
    "            sess.run(iterator.initializer)\n",
    "            while True:\n",
    "                try:\n",
    "                    value = sess.run(next_element)\n",
    "                    print(\"Num Batch: \", num_batch)\n",
    "                    print(\"Batch value: \", value)\n",
    "                    #assert j == value\n",
    "                    #j += 1\n",
    "                    num_batch += 1\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/recsys/dataset/train/2020-05-08-00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/recsys/dataset/train/2020-05-08-00/train\n",
      "/home/recsys/dataset/train/2020-05-08-00/test\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(path+\"/train\")\n",
    "test = load_dataset(path+\"/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in train.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 选择特征列 \n",
    "uid, u_umi, u_umi_weight, u_uli, u_uli_weight, u_usi, u_usi_weight, u_level\n",
    "\n",
    "t_channel, t_location\n",
    "\n",
    "item_id, cp_l1_category, cp_interests, cp_location, cp_publisher, cp_media_level, cp_life_hour\n",
    "\n",
    "rs_channel, rs_gactr, rs_taginfo, rs_taginfo_weight, rs_dactr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "class NumpyFunctionHelper:\n",
    "    def __init__(self, maxlen=None, dtype='int32', padding='post', truncating='post', value=0.0):\n",
    "        self.maxlen = maxlen\n",
    "        self.dtype = dtype\n",
    "        self.padding = padding\n",
    "        self.truncating = truncating\n",
    "        self.value = value\n",
    "        self.out_dtype = tf.int32\n",
    "        if self.dtype == 'int64':\n",
    "            self.out_dtype = tf.int64\n",
    "        elif self.dtype == 'float32':\n",
    "            self.out_dtype = tf.float32\n",
    "        return\n",
    "\n",
    "    def pad_sequences(self, x):\n",
    "        # x will be a numpy array with the contents of the input to the\n",
    "        # tf.function\n",
    "        # note: x will be processed as a list of sequences\n",
    "        return sequence.pad_sequences(x,\n",
    "                                      maxlen = self.maxlen,\n",
    "                                      dtype = self.dtype,\n",
    "                                      padding = self.padding,\n",
    "                                      truncating = self.truncating,\n",
    "                                      value = self.value)\n",
    "\n",
    "    # tf.numpy_function用于将一个numpy函数转换为一个tensor的operator，以便嵌入到计算图中处理Tensor\n",
    "    # 构造一个能支持Tensor的填充截断函数\n",
    "    # 调用方法NumpyFunctionHelper.tf_pad_sequences(helper, in_tensor)\n",
    "    @tf.function\n",
    "    def tf_pad_sequences(self, in_tensor):\n",
    "        y = tf.numpy_function(self.pad_sequences, [in_tensor], self.out_dtype)\n",
    "        return y\n",
    "\n",
    "    # 毫秒时间戳转换为local的struct_time\n",
    "    def timestamp_to_time(self, ts):\n",
    "        st = time.localtime(ts/1000)\n",
    "        return tf.constant([st.tm_mon, st.tm_mday, st.tm_hour, st.tm_min, st.tm_wday])\n",
    "\n",
    "    @tf.function\n",
    "    def tf_timestamp_to_time(self, ts):\n",
    "        y = tf.py_function(self.timestamp_to_time, ts, self.out_dtype)\n",
    "        return y\n",
    "    \n",
    "    def pad_str_sequences(self, x):\n",
    "        lst = x.tolist()\n",
    "        res = []\n",
    "        if len(x) < self.maxlen:\n",
    "            for i in range(self.maxlen - len(x)):\n",
    "                res.append(b'<PAD>')\n",
    "\n",
    "        return np.asarray(lst + res)[:self.maxlen]\n",
    "    \n",
    "    @tf.function\n",
    "    def tf_pad_str_sequences(self, in_tensor):\n",
    "        y = tf.numpy_function(self.pad_str_sequences, [in_tensor], tf.string)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "def pad_sequences(x):\n",
    "    # x will be a numpy array with the contents of the input to the\n",
    "    # tf.function\n",
    "    # note: x will be processed as a list of sequences\n",
    "    lst = x.tolist()\n",
    "    res = []\n",
    "    if len(x) < max_len:\n",
    "        for i in range(max_len - len(x)):\n",
    "            res.append(b'<PAD>')\n",
    "            \n",
    "    return np.asarray(lst + res)[:max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_pad_sequences(in_tensor):\n",
    "    y = tf.numpy_function(pad_sequences, [in_tensor], tf.string)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Every feature: ['cp_interests', 'rs_taginfo', 'u_uli', 'item_id', 'rs_gactr']\n",
      "A batch of u_uli: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "A batch of rs_taginfo: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "A batch of targets: tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0], shape=(64,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def parse_function(example_proto):\n",
    "    dics = {'action': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'uid': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            'u_uli': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'u_uli_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "#             'u_umi': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'u_umi_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "#             'u_usi': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'u_usi_weight': tf.io.VarLenFeature( dtype=tf.float32),\n",
    "#             'u_level': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=b'0'),\n",
    "#             't_channel': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "#             't_location': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'item_id': tf.io.FixedLenFeature(shape=(1,), dtype=tf.string, default_value=''),\n",
    "#             't_action': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=1),\n",
    "#             't_scene': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "#             'cp_word_count': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_media_level': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_publisher': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "#             'cp_is_local_publisher': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_location': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'cp_is_local': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_l1_category': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'cp_life_hour': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=72),\n",
    "            'cp_interests': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_gactr': tf.io.FixedLenFeature(shape=(), dtype=tf.float32, default_value=0),\n",
    "#             'rs_channel': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_taginfo': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'rs_dactr': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "           }\n",
    "    # parse all features in a single example according to the dics\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, dics)\n",
    "    \n",
    "    max_len = 300\n",
    "    h = NumpyFunctionHelper(maxlen=max_len, dtype=tf.string, value=b'<PAD>')\n",
    "    parsed_example['u_uli'] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example['u_uli']))\n",
    "    parsed_example['u_uli'].set_shape([max_len])\n",
    "    \n",
    "    max_len = 10\n",
    "    h = NumpyFunctionHelper(maxlen=max_len, dtype=tf.string, value=b'<PAD>')\n",
    "    parsed_example['rs_taginfo'] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example['rs_taginfo']))\n",
    "    parsed_example['rs_taginfo'].set_shape([max_len])\n",
    "    \n",
    "    max_len = 8\n",
    "    h = NumpyFunctionHelper(maxlen=max_len, dtype=tf.string, value=b'<PAD>')\n",
    "    parsed_example['cp_interests'] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example['cp_interests']))\n",
    "    parsed_example['cp_interests'].set_shape([max_len])\n",
    "#     parsed_example['cp_media_level'] = tf.strings.as_string(parsed_example['cp_media_level'])\n",
    "    target = parsed_example['action']\n",
    "    del parsed_example['action']\n",
    "    return parsed_example, target\n",
    "train_dataset = train.map(parse_function)\n",
    "test_dataset = test.map(parse_function)\n",
    "\n",
    "new_dataset = train_dataset\n",
    "new_dataset = new_dataset.batch(64)\n",
    "example_batch = next(iter(new_dataset))[0]\n",
    "\n",
    "# # feature_column.categorical_column_with_vocabulary_list(key='u_level', vocabulary_list=u_levels, num_oov_buckets=1)\n",
    "for feature_batch, label_batch in new_dataset.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "#     print('A batch of u_uli:', feature_batch['u_uli'])\n",
    "    print('A batch of u_uli:', type(feature_batch['u_uli']))\n",
    "#     print('A batch of item_id:', feature_batch['u_uli'])\n",
    "    print('A batch of rs_taginfo:', type(feature_batch['rs_taginfo']))\n",
    "    print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7f60d01441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Every feature: ['cp_interests', 'rs_taginfo', 'u_uli', 'item_id', 'rs_gactr']\n",
      "A batch of u_uli: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1142/1142 [==============================] - 352s 308ms/step - loss: 0.2749 - binary_crossentropy: 0.2749 - accuracy: 0.8991 - auc_1: 0.7887 - val_loss: 0.3597 - val_binary_crossentropy: 0.3653 - val_accuracy: 0.8980 - val_auc_1: 0.6681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6168475c18>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_function(example_proto):\n",
    "    dics = {'action': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'uid': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            'u_uli': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'u_uli_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "#             'u_umi': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'u_umi_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "#             'u_usi': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'u_usi_weight': tf.io.VarLenFeature( dtype=tf.float32),\n",
    "#             'u_level': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=b'0'),\n",
    "#             't_channel': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "#             't_location': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'item_id': tf.io.FixedLenFeature(shape=(1,), dtype=tf.string, default_value=''),\n",
    "#             't_action': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=1),\n",
    "#             't_scene': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "#             'cp_word_count': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_media_level': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_publisher': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "#             'cp_is_local_publisher': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_location': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'cp_is_local': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "#             'cp_l1_category': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'cp_life_hour': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=72),\n",
    "            'cp_interests': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_gactr': tf.io.FixedLenFeature(shape=(), dtype=tf.float32, default_value=0),\n",
    "#             'rs_channel': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_taginfo': tf.io.VarLenFeature(dtype=tf.string),\n",
    "#             'rs_dactr': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "           }\n",
    "    # parse all features in a single example according to the dics\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, dics)\n",
    "    \n",
    "    max_len = 300\n",
    "    h = NumpyFunctionHelper(maxlen=max_len, dtype=tf.string, value=b'<PAD>')\n",
    "    parsed_example['u_uli'] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example['u_uli']))\n",
    "    parsed_example['u_uli'].set_shape([max_len])\n",
    "    \n",
    "    max_len = 10\n",
    "    h = NumpyFunctionHelper(maxlen=max_len, dtype=tf.string, value=b'<PAD>')\n",
    "    parsed_example['rs_taginfo'] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example['rs_taginfo']))\n",
    "    parsed_example['rs_taginfo'].set_shape([max_len])\n",
    "    \n",
    "    max_len = 8\n",
    "    h = NumpyFunctionHelper(maxlen=max_len, dtype=tf.string, value=b'<PAD>')\n",
    "    parsed_example['cp_interests'] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example['cp_interests']))\n",
    "    parsed_example['cp_interests'].set_shape([max_len])\n",
    "#     parsed_example['cp_media_level'] = tf.strings.as_string(parsed_example['cp_media_level'])\n",
    "    target = parsed_example['action']\n",
    "    del parsed_example['action']\n",
    "    return parsed_example, target\n",
    "train_dataset = train.map(parse_function)\n",
    "test_dataset = test.map(parse_function)\n",
    "\n",
    "new_dataset = train_dataset\n",
    "new_dataset = new_dataset.batch(64)\n",
    "example_batch = next(iter(new_dataset))[0]\n",
    "\n",
    "# # feature_column.categorical_column_with_vocabulary_list(key='u_level', vocabulary_list=u_levels, num_oov_buckets=1)\n",
    "for feature_batch, label_batch in new_dataset.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "#     print('A batch of u_uli:', feature_batch['u_uli'])\n",
    "    print('A batch of u_uli:', type(feature_batch['u_uli']))\n",
    "#     print('A batch of item_id:', feature_batch['u_uli'])\n",
    "#     print('A batch of rs_taginfo:', feature_batch['rs_taginfo'])\n",
    "#     print('A batch of targets:', label_batch )\n",
    "    \n",
    "# 用于创建一个特征列\n",
    "# 并转换一批次数据的一个实用程序方法\n",
    "def demo(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(example_batch).numpy()\n",
    "\n",
    "#选择特征列\n",
    "feature_columns = []\n",
    "feature_layer_inputs = {}\n",
    "\n",
    "feature_columns.append(feature_column.numeric_column(\"rs_gactr\"))\n",
    "feature_layer_inputs[\"rs_gactr\"] = tf.keras.Input(shape=(1,), name=\"rs_gactr\", dtype='float32')\n",
    "\n",
    "item_id_hash = feature_column.categorical_column_with_hash_bucket('item_id', hash_bucket_size=500000)\n",
    "item_id_one_hot = feature_column.indicator_column(item_id_hash)\n",
    "feature_columns.append(item_id_one_hot)\n",
    "feature_layer_inputs['item_id'] = tf.keras.Input(shape=(1,), name='item_id', dtype=tf.string)\n",
    "item_id_embedding = feature_column.embedding_column(item_id_hash, dimension=64)\n",
    "feature_columns.append(item_id_embedding)\n",
    "\n",
    "# uid_hash = feature_column.categorical_column_with_hash_bucket('uid', hash_bucket_size=500000)\n",
    "# uid_embedding = feature_column.embedding_column(uid_hash, dimension=64)\n",
    "# feature_columns.append(uid_embedding)\n",
    "# feature_layer_inputs[\"uid\"] = tf.keras.Input(shape=(), name=\"uid\", dtype='string')\n",
    "\n",
    "\n",
    "u_uli = feature_column.categorical_column_with_hash_bucket('u_uli', hash_bucket_size=30000, dtype=tf.string)\n",
    "u_uli_one_hot = feature_column.indicator_column(u_uli)\n",
    "feature_columns.append(u_uli_one_hot)\n",
    "feature_layer_inputs[\"u_uli\"] = tf.keras.Input(shape=(300,), name=\"u_uli\", dtype=tf.string)\n",
    "u_uli_embedding = feature_column.embedding_column(u_uli, dimension=64)\n",
    "feature_columns.append(u_uli_embedding)\n",
    "\n",
    "# feature_layer_inputs[\"u_uli\"] = tf.keras.Input(shape=(1,), sparse=True, dtype=tf.string, name=\"u_uli\")\n",
    "\n",
    "# u_umi = feature_column.categorical_column_with_vocabulary_list('u_umi', vocabulary_list=its, num_oov_buckets=1)\n",
    "# u_umi_embedding = feature_column.embedding_column(u_umi, dimension=64)\n",
    "# feature_columns.append(u_umi_embedding)\n",
    "\n",
    "# u_usi = feature_column.categorical_column_with_vocabulary_list('u_usi', vocabulary_list=its, num_oov_buckets=1)\n",
    "# u_usi_embedding = feature_column.embedding_column(u_usi, dimension=64)\n",
    "# feature_columns.append(u_usi_embedding)\n",
    "\n",
    "# u_level = feature_column.categorical_column_with_vocabulary_list('u_level', vocabulary_list=u_levels, num_oov_buckets=1)\n",
    "# u_level_one_hot = feature_column.indicator_column(u_level)\n",
    "# feature_columns.append(u_level_one_hot)\n",
    "\n",
    "# t_channel = feature_column.categorical_column_with_vocabulary_list('t_channel', vocabulary_list=channels, num_oov_buckets=1)\n",
    "# t_channel_one_hot = feature_column.indicator_column(t_channel)\n",
    "# feature_columns.append(t_channel_one_hot)\n",
    "\n",
    "# t_location = feature_column.categorical_column_with_vocabulary_list('t_location', vocabulary_list=locs, num_oov_buckets=1)\n",
    "# t_location_one_hot = feature_column.indicator_column(t_location)\n",
    "# feature_columns.append(t_location_one_hot)\n",
    "\n",
    "# cp_media_level = feature_column.categorical_column_with_vocabulary_list('cp_media_level', vocabulary_list=media_levels, num_oov_buckets=1)\n",
    "# cp_media_level_one_hot = feature_column.indicator_column(cp_media_level)\n",
    "# feature_columns.append(cp_media_level_one_hot)\n",
    "\n",
    "# cp_publisher = feature_column.categorical_column_with_vocabulary_list('cp_publisher', vocabulary_list=publishers, num_oov_buckets=1)\n",
    "# cp_publisher_one_hot = feature_column.indicator_column(cp_publisher)\n",
    "# feature_columns.append(cp_publisher_one_hot)\n",
    "\n",
    "# cp_location = feature_column.categorical_column_with_vocabulary_list('cp_location', vocabulary_list=locs, num_oov_buckets=1)\n",
    "# cp_location_embedding = feature_column.embedding_column(cp_location, dimension=8)\n",
    "# feature_columns.append(cp_location_embedding)\n",
    "\n",
    "# cp_life_hour = feature_column.numeric_column(\"cp_life_hour\")\n",
    "# cp_life_hour = feature_column.bucketized_column(cp_life_hour, boundaries=[72, 24 * 7, 24 * 14, 24 * 30])\n",
    "# feature_columns.append(cp_life_hour)\n",
    "\n",
    "# rs_channel = feature_column.categorical_column_with_vocabulary_list('rs_channel', vocabulary_list=rschannles, num_oov_buckets=1)\n",
    "# rs_channel_embedding = feature_column.embedding_column(rs_channel, dimension=6)\n",
    "# feature_columns.append(rs_channel_embedding)\n",
    "\n",
    "# rs_taginfo = feature_column.categorical_column_with_vocabulary_list('rs_taginfo', vocabulary_list=its, num_oov_buckets=1)\n",
    "# rs_taginfo_embedding = feature_column.embedding_column(rs_taginfo, dimension=8)\n",
    "# feature_columns.append(rs_taginfo_embedding)\n",
    "\n",
    "rs_taginfo = feature_column.categorical_column_with_hash_bucket('rs_taginfo', hash_bucket_size=30000, dtype=tf.string)\n",
    "rs_taginfo_one_hot = feature_column.indicator_column(rs_taginfo)\n",
    "feature_columns.append(rs_taginfo_one_hot)\n",
    "feature_layer_inputs[\"rs_taginfo\"] = tf.keras.Input(shape=(10,), name=\"rs_taginfo\", dtype=tf.string)\n",
    "rs_taginfo_embedding = feature_column.embedding_column(rs_taginfo, dimension=8)\n",
    "feature_columns.append(rs_taginfo_embedding)\n",
    "\n",
    "#构造输入特征\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "batch_size = 128\n",
    "buffer_size = 5000\n",
    "train_dataset = train_dataset.repeat(10).shuffle(buffer_size).batch(batch_size)\n",
    "test_dataset = test_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "\n",
    "#定义模型\n",
    "dense1 = tf.keras.layers.Dense(128, activation='relu')(feature_layer_outputs)\n",
    "dense2 = tf.keras.layers.Dense(64, activation='relu')(dense1)\n",
    "dense3 = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "model = tf.keras.Model(inputs=feature_layer_inputs, outputs=dense3)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_crossentropy', 'accuracy', tf.keras.metrics.AUC()],\n",
    "              run_eagerly=True)\n",
    "\n",
    "# 模型训练\n",
    "model.fit(train_dataset,\n",
    "          validation_data=test_dataset,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, \"deepfm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18971294  0.04961373 -0.19117878 ...  0.04181842  0.0559338\n",
      "  -0.0354376 ]\n",
      " [-0.12126184 -0.01599275 -0.01602121 ...  0.24969533 -0.00577582\n",
      "   0.01080038]\n",
      " [-0.12126184 -0.01599275 -0.01602121 ...  0.24969533 -0.00577582\n",
      "   0.01080038]\n",
      " ...\n",
      " [ 0.23176633 -0.0812902  -0.00957167 ...  0.19255221  0.19825476\n",
      "   0.08748969]\n",
      " [-0.12886588  0.01968288 -0.01812283 ... -0.22047816  0.2085035\n",
      "  -0.09212628]\n",
      " [-0.06101322  0.00323148  0.07808689 ...  0.15657379  0.02938868\n",
      "  -0.02438149]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo(item_id_embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature_batch, label_batch in train_dataset.take(1):\n",
    "#     print('Every feature:', list(feature_batch.keys()))\n",
    "#     print(type(feature_batch['item_id']))\n",
    "#     print(type(feature_batch['uid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = tf.keras.layers.Dense(128, activation='relu')(feature_layer_outputs)\n",
    "dense2 = tf.keras.layers.Dense(64, activation='relu')(dense1)\n",
    "dense3 = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "model = tf.keras.Model(inputs=feature_layer_inputs, outputs=dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_crossentropy', 'accuracy', tf.keras.metrics.AUC()],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, \"deepfm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /home/recsys/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /home/recsys/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /home/recsys/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected item_id to have 2 dimensions, but got array with shape (None, None, None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-6c68d7ebfe98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_dataset,\n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=1)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /home/recsys/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /home/recsys/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /home/recsys/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected item_id to have 2 dimensions, but got array with shape (None, None, None)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "          validation_data=test_dataset,\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyExampleModel(feature_columns, field_metas, learning_rate=0.01):\n",
    "    feature_layer_inputs = dict()\n",
    "    for fm in field_metas:\n",
    "        feature_layer_inputs[fm.name] = tf.keras.Input(shape=(fm.shape), name=fm.name, dtype=fm.dtype)\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu')(feature_layer_outputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    pred = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=pred)\n",
    "\n",
    "def loss(output, labels):\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    return tf.reduce_mean(\n",
    "        input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=output, labels=labels\n",
    "        )\n",
    "    )\n",
    "\n",
    "def optimizer(lr=0.1):\n",
    "    return tf.optimizers.SGD(lr)\n",
    "\n",
    "def prepare_prediction_column(self, prediction):\n",
    "    \"\"\"Return the class label of highest probability.\"\"\"\n",
    "    return prediction.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
