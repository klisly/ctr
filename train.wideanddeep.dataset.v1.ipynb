{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import os\n",
    "from functools import cmp_to_key\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from deepctr.inputs import SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names\n",
    "from deepctr.models import DeepFM\n",
    "import pickle\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "3.6\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)\n",
    "print('{}.{}'.format(sys.version_info.major,sys.version_info.minor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_from_file(file, type='default', skiprow = 0):\n",
    "    data = list()\n",
    "    size = 0\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            size += 1\n",
    "            try:\n",
    "                if size <= skiprow:\n",
    "                    continue\n",
    "                line = line.replace('\"', '').strip()\n",
    "                if len(line) <= 0:\n",
    "                    continue\n",
    "                if type == 'interet':\n",
    "                    parts = line.split(\",\")\n",
    "                    name = parts[0]\n",
    "                    size = int(parts[1])\n",
    "                    if size > 10 and len(name) > 0:\n",
    "                        data.append(name)\n",
    "                elif type == 'loc':\n",
    "                    parts = line.split(\",\")\n",
    "                    province = parts[0]\n",
    "                    city = parts[1]\n",
    "                    area = parts[2]\n",
    "                    data.append(province)\n",
    "                    data.append(province + \"_\" + city)\n",
    "                    data.append(province + \"_\" + city + \"_\" + area)\n",
    "                elif type == 'publisher':\n",
    "                    parts = line.split(\",\")\n",
    "                    name = parts[0]\n",
    "                    size = int(parts[1])\n",
    "                    if size > 10:\n",
    "                        data.append(name)\n",
    "                else:\n",
    "                    data.append(line)\n",
    "            except:\n",
    "                print(line)\n",
    "    return data\n",
    "\n",
    "def load_dict(dir, type='default', skiprow = 0):\n",
    "    data = list()\n",
    "    size = 0\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "        data+=load_dict_from_file(dir + \"/\" + file, type, skiprow)\n",
    "    return list(set(data))\n",
    "\n",
    "def save_pickle_data(file, data):\n",
    "    f = open(file, 'wb')\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def load_pickle_data(file):\n",
    "    try:\n",
    "        f1 = open(file, 'rb')\n",
    "        return pickle.load(f1)\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "lbe_file = 'lbe.pickle'\n",
    "data_map_file = 'data_map.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky game\n",
      "中国新闻网,绥芬河政府网站,1\n",
      "Ansun Biopharma, Inc.,1\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/data10t/mgf/datas/info'\n",
    "its = load_dict(base_dir+'/dict/interets', 'interet')\n",
    "locs = load_dict(base_dir+'/dict/loc', 'loc')\n",
    "publishers = load_dict(base_dir+'/dict/publisher', 'publisher', 1)\n",
    "cates = load_dict_from_file(base_dir+'/dict/cate.csv', 'cate', 1)\n",
    "channels = load_dict_from_file(base_dir+'/dict/channel.csv', 'channel', 1)\n",
    "\n",
    "u_levels = [str(i) for i in range(0, 10)]\n",
    "media_levels = [str(i) for i in range(0, 10)]\n",
    "rschannles = [str(i) for i in range(1, 33)]\n",
    "vocabs = dict()\n",
    "vocabs['u_level'] = u_levels\n",
    "vocabs['t_channel'] = channels\n",
    "vocabs['cp_l1_category'] = cates\n",
    "vocabs['cp_publisher'] = publishers\n",
    "vocabs['cp_media_level'] = media_levels\n",
    "vocabs['rschannles'] = rschannles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_paths):\n",
    "    files = []\n",
    "    for dir_path in dir_paths:\n",
    "        files += os.listdir(dir_path)\n",
    "        print(dir_path)\n",
    "    dataset = tf.data.TFRecordDataset(filenames = [dir_path + '/' + file for file in files], num_parallel_reads = 32)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort_files(dir):\n",
    "    def compare(x, y):\n",
    "        stat_x = int(x.replace('-', ''))\n",
    "        stat_y = int(y.replace('-', ''))\n",
    "        if stat_x < stat_y:\n",
    "            return -1\n",
    "        elif stat_x > stat_y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    items = os.listdir(dir)\n",
    "    items.sort(key = cmp_to_key(compare))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-20-00  2020-05-20-18  2020-05-21-12  2020-05-22-06  2020-05-23-00\n",
      "2020-05-20-01  2020-05-20-19  2020-05-21-13  2020-05-22-07  2020-05-23-01\n",
      "2020-05-20-02  2020-05-20-20  2020-05-21-14  2020-05-22-08  2020-05-23-02\n",
      "2020-05-20-03  2020-05-20-21  2020-05-21-15  2020-05-22-09  2020-05-23-03\n",
      "2020-05-20-04  2020-05-20-22  2020-05-21-16  2020-05-22-10  2020-05-23-04\n",
      "2020-05-20-05  2020-05-20-23  2020-05-21-17  2020-05-22-11  2020-05-23-05\n",
      "2020-05-20-06  2020-05-21-00  2020-05-21-18  2020-05-22-12  2020-05-23-06\n",
      "2020-05-20-07  2020-05-21-01  2020-05-21-19  2020-05-22-13  2020-05-23-07\n",
      "2020-05-20-08  2020-05-21-02  2020-05-21-20  2020-05-22-14  2020-05-23-08\n",
      "2020-05-20-09  2020-05-21-03  2020-05-21-21  2020-05-22-15  2020-05-23-09\n",
      "2020-05-20-10  2020-05-21-04  2020-05-21-22  2020-05-22-16  2020-05-23-10\n",
      "2020-05-20-11  2020-05-21-05  2020-05-21-23  2020-05-22-17  2020-05-23-11\n",
      "2020-05-20-12  2020-05-21-06  2020-05-22-00  2020-05-22-18  2020-05-23-12\n",
      "2020-05-20-13  2020-05-21-07  2020-05-22-01  2020-05-22-19  2020-05-23-13\n",
      "2020-05-20-14  2020-05-21-08  2020-05-22-02  2020-05-22-20  2020-05-23-14\n",
      "2020-05-20-15  2020-05-21-09  2020-05-22-03  2020-05-22-21  2020-05-23-15\n",
      "2020-05-20-16  2020-05-21-10  2020-05-22-04  2020-05-22-22  2020-05-23-16\n",
      "2020-05-20-17  2020-05-21-11  2020-05-22-05  2020-05-22-23  2020-05-23-17\n",
      "Please check the latest version manually on https://pypi.org/project/deepctr/#history\n"
     ]
    }
   ],
   "source": [
    "!ls /data10t/mgf/datas/info/train_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/data10t/mgf/datas/info/train_v2'\n",
    "files = list_sort_files(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [dir + \"/\" + file + \"/train\" for file in files[:-2]] + [dir + \"/\" + file + \"/test\" for file in files[:-2]]\n",
    "test_files = [dir + \"/\" + file + \"/train\" for file in files[-2:]] + [dir + \"/\" + file + \"/test\" for file in files[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train dataset\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-00/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-01/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-02/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-03/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-04/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-05/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-06/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-07/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-08/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-09/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-10/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-11/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-12/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-13/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-14/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-15/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-16/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-17/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-18/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-19/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-20/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-21/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-22/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-23/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-00/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-01/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-02/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-03/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-04/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-05/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-06/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-07/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-08/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-09/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-10/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-11/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-12/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-13/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-14/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-15/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-16/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-17/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-18/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-19/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-20/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-21/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-22/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-23/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-00/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-01/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-02/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-03/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-04/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-05/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-06/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-07/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-08/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-09/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-10/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-11/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-12/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-13/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-14/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-15/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-16/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-17/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-18/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-19/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-20/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-21/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-22/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-23/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-00/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-01/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-02/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-03/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-04/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-05/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-06/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-07/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-08/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-09/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-10/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-11/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-12/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-13/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-14/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-15/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-00/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-01/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-02/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-03/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-04/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-05/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-06/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-07/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-08/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-09/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-10/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-11/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-12/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-13/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-14/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-15/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-16/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-17/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-18/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-19/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-20/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-21/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-22/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-20-23/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-00/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-01/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-02/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-03/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-04/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-05/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-06/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-07/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-08/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-09/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-10/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-11/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-12/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-13/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-14/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-15/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-16/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-17/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-18/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-19/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-20/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-21/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-22/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-21-23/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-00/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-01/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-02/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-03/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-04/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-05/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-06/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-07/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-08/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-09/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-10/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-11/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-12/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-13/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-14/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-15/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-16/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-17/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-18/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-19/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-20/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-21/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-22/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-22-23/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-00/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-01/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-02/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-03/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-04/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-05/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-06/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-07/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-08/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-09/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-10/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-11/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-12/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-13/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-14/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-15/test\n",
      "load test dataset\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-16/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-17/train\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-16/test\n",
      "/data10t/mgf/datas/info/train_v2/2020-05-23-17/test\n"
     ]
    }
   ],
   "source": [
    "print(\"load train dataset\")\n",
    "train = load_dataset(train_files)\n",
    "print(\"load test dataset\")\n",
    "test = load_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.core.example.example_pb2.Example'>\n"
     ]
    }
   ],
   "source": [
    "for raw_record in train.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(type(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于创建一个特征列\n",
    "# 并转换一批次数据的一个实用程序方法\n",
    "def demo(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(example_batch).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 选择特征列 \n",
    "uid, u_umi, u_umi_weight, u_uli, u_uli_weight, u_usi, u_usi_weight, u_level\n",
    "\n",
    "t_channel, t_location\n",
    "\n",
    "item_id, cp_l1_category, cp_interests, cp_location, cp_publisher, cp_media_level, cp_life_hour\n",
    "\n",
    "rs_channel, rs_gactr, rs_taginfo, rs_taginfo_weight, rs_dactr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "class NumpyFunctionHelper:\n",
    "    def __init__(self, maxlen=None, dtype='int32', padding='post', truncating='post', value=0.0):\n",
    "        self.maxlen = maxlen\n",
    "        self.dtype = dtype\n",
    "        self.padding = padding\n",
    "        self.truncating = truncating\n",
    "        self.value = value\n",
    "        self.out_dtype = tf.int32\n",
    "        if self.dtype == 'int64':\n",
    "            self.out_dtype = tf.int64\n",
    "        elif self.dtype == 'float32':\n",
    "            self.out_dtype = tf.float32\n",
    "        elif self.dtype == 'str':\n",
    "            self.out_dtype = tf.string\n",
    "        return\n",
    "\n",
    "    def pad_sequences(self, x):\n",
    "        # x will be a numpy array with the contents of the input to the\n",
    "        # tf.function\n",
    "        # note: x will be processed as a list of sequences\n",
    "        return sequence.pad_sequences(x,\n",
    "                                      maxlen = self.maxlen,\n",
    "                                      dtype = self.dtype,\n",
    "                                      padding = self.padding,\n",
    "                                      truncating = self.truncating,\n",
    "                                      value = self.value)\n",
    "\n",
    "    # tf.numpy_function用于将一个numpy函数转换为一个tensor的operator，以便嵌入到计算图中处理Tensor\n",
    "    # 构造一个能支持Tensor的填充截断函数\n",
    "    # 调用方法NumpyFunctionHelper.tf_pad_sequences(helper, in_tensor)\n",
    "    @tf.function()\n",
    "    def tf_pad_sequences(self, in_tensor):\n",
    "        y = tf.numpy_function(self.pad_sequences, [in_tensor], self.out_dtype)\n",
    "        return y\n",
    "\n",
    "    # 毫秒时间戳转换为local的struct_time\n",
    "    def timestamp_to_time(self, ts):\n",
    "        st = time.localtime(ts/1000)\n",
    "        return tf.constant([st.tm_mon, st.tm_mday, st.tm_hour, st.tm_min, st.tm_wday])\n",
    "\n",
    "    @tf.function()\n",
    "    def tf_timestamp_to_time(self, ts):\n",
    "        y = tf.py_function(self.timestamp_to_time, ts, self.out_dtype)\n",
    "        return y\n",
    "    \n",
    "    def pad_float_sequences(self, x):\n",
    "        lst = x.tolist()\n",
    "        res = []\n",
    "        if len(x) < self.maxlen:\n",
    "            for i in range(self.maxlen - len(x)):\n",
    "                res.append(0.0)\n",
    "\n",
    "        return np.asarray(lst + res, dtype=np.float32)[:self.maxlen]\n",
    "    \n",
    "    @tf.function()\n",
    "    def tf_pad_float_sequences(self, in_tensor):\n",
    "        y = tf.numpy_function(self.pad_float_sequences, [in_tensor], tf.float32)\n",
    "        return y\n",
    "    \n",
    "    def pad_str_sequences(self, x):\n",
    "        lst = x.tolist()\n",
    "        res = []\n",
    "        if len(x) < self.maxlen:\n",
    "            for i in range(self.maxlen - len(x)):\n",
    "                res.append(b'<PAD>')\n",
    "\n",
    "        return np.asarray(lst + res)[:self.maxlen]\n",
    "    \n",
    "    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n",
    "    def tf_pad_str_sequences(self, in_tensor):\n",
    "        y = tf.numpy_function(self.pad_str_sequences, [in_tensor], tf.string)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data use type \n",
    "long interest 50 middle interest 20 short interest 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc = \"t_location:3;u_uli_interest:50;u_uli_interest_weight:50;u_uli_cate:10;u_uli_cate_weight:10;\"\\\n",
    "+\"u_umi_interest:20;u_umi_interest_weight:20;u_umi_cate:10;u_umi_cate_weight:10;\"\\\n",
    "+\"u_usi_interest:15;u_usi_interest_weight:15;u_usi_cate:5;u_usi_cate_weight:5;\"\\\n",
    "+\"cp_category:3;cp_category_weight:3;cp_interests:8;cp_interests_weight:8;cp_location:3;cp_location_weight:3;\"\\\n",
    "+\"rs_channel:16;\"\\\n",
    "+\"rs_tag_interest:8;rs_tag_interest_dactr:8;rs_tag_cate:3;rs_tag_cate_dactr:3\"\n",
    "sparse_configs = [{'key':item.split(\":\")[0], 'max_len':int(item.split(\":\")[1])} for item in spc.split(\";\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in sparse_configs:\n",
    "    key = config['key']\n",
    "    max_len = config['max_len']\n",
    "    dtype=tf.string\n",
    "    value=b'<PAD>'\n",
    "    if key.endswith('weight') or key.endswith('dactr'):\n",
    "        dtype=tf.float32\n",
    "        value=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_location\n",
      "u_uli_interest\n",
      "u_uli_interest_weight\n",
      "u_uli_cate\n",
      "u_uli_cate_weight\n",
      "u_umi_interest\n",
      "u_umi_interest_weight\n",
      "u_umi_cate\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_umi_cate_weight\n",
      "u_usi_interest\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_interest_weight\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_cate\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_cate_weight\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_category\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_category_weight\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_interests\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_interests_weight\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_location\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_location_weight\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_channel\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_interest\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_interest_dactr\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_cate\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_cate_dactr\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "t_location\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_uli_interest\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_uli_interest_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_uli_cate\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_uli_cate_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_umi_interest\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_umi_interest_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_umi_cate\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_umi_cate_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_interest\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_interest_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_cate\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "u_usi_cate_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_category\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_category_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_interests\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_interests_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_location\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "cp_location_weight\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_channel\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_interest\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_interest_dactr\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_cate\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_str_sequences at 0x7fc10d43f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "rs_tag_cate_dactr\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function NumpyFunctionHelper.tf_pad_float_sequences at 0x7fc10d43f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Every feature: ['cp_category', 'cp_category_weight', 'cp_interests', 'cp_interests_weight', 'cp_location', 'cp_location_weight', 'rs_channel', 'rs_tag_cate', 'rs_tag_cate_dactr', 'rs_tag_interest', 'rs_tag_interest_dactr', 't_location', 'u_uli_cate', 'u_uli_cate_weight', 'u_uli_interest', 'u_uli_interest_weight', 'u_umi_cate', 'u_umi_cate_weight', 'u_umi_interest', 'u_umi_interest_weight', 'u_usi_cate', 'u_usi_cate_weight', 'u_usi_interest', 'u_usi_interest_weight', 'cp_clickbait_type', 'cp_is_local', 'cp_is_local_publisher', 'cp_life_hour', 'cp_list_image_count', 'cp_media_level', 'cp_newsy_score', 'cp_product_type', 'cp_publish_time', 'cp_publisher', 'cp_vulgar_type', 'cp_word_count', 'item_id', 'report_time', 'request_id', 'rs_gactr', 'rs_p1_score', 't_action', 't_channel', 't_country', 't_ctype', 't_ip', 't_language', 't_pid', 't_scene', 'u_level', 'uid']\n",
      "A batch of request_id: tf.Tensor(\n",
      "[b'26b1c3a61e2444b9b5cb7c0355779f8b8835e4b7'\n",
      " b'3b25c13d20a6990bea0b7092a3f396cf36cfdce4'], shape=(2,), dtype=string)\n",
      "A batch of u_uli_interest_weight: tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]], shape=(2, 50), dtype=float32)\n",
      "A batch of targets: tf.Tensor([1 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def parse_function(example_proto):\n",
    "    dics = {\n",
    "            'request_id':tf.io.FixedLenFeature(shape=(),dtype=tf.string, default_value=''),\n",
    "            'report_time': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_language': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_country': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_pid': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_ip': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_channel': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_scene': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            't_action': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            't_ctype': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            't_location': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'uid': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            'u_level': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'u_uli_interest': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'u_uli_interest_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'u_uli_cate': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'u_uli_cate_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'u_umi_interest': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'u_umi_interest_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'u_umi_cate': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'u_umi_cate_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'u_usi_interest': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'u_usi_interest_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'u_usi_cate': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'u_usi_cate_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'item_id': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            'cp_publisher': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            'cp_media_level': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_publish_time': tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=''),\n",
    "            'cp_life_hour': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_newsy_score': tf.io.FixedLenFeature(shape=(), dtype=tf.float32, default_value=0),\n",
    "            'cp_word_count': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_category': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'cp_category_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'cp_interests': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'cp_interests_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'cp_location': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'cp_location_weight': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'cp_list_image_count': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_clickbait_type': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_vulgar_type': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_product_type': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_is_local': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'cp_is_local_publisher': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "            'rs_channel': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_p1_score': tf.io.FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0),\n",
    "            'rs_gactr': tf.io.FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0),\n",
    "            'rs_tag_interest': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_tag_interest_dactr': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'rs_tag_cate': tf.io.VarLenFeature(dtype=tf.string),\n",
    "            'rs_tag_cate_dactr': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "            'action': tf.io.FixedLenFeature(shape=(), dtype=tf.int64, default_value=0),\n",
    "           }\n",
    "    # parse all features in a single example according to the dics\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, dics)\n",
    "    for config in sparse_configs:\n",
    "        key = config['key']\n",
    "        print(key)\n",
    "        dtype='str'\n",
    "        value=b'<PAD>'\n",
    "        if key.endswith('weight') or key.endswith('dactr'):\n",
    "            dtype='float32'\n",
    "            value=0.0\n",
    "            h = NumpyFunctionHelper(maxlen=config['max_len'], dtype=dtype, value=value)\n",
    "            parsed_example[key] = NumpyFunctionHelper.tf_pad_float_sequences(h, tf.sparse.to_dense(parsed_example[key]))\n",
    "            parsed_example[key].set_shape([config['max_len']])\n",
    "        else:\n",
    "            h = NumpyFunctionHelper(maxlen=config['max_len'], dtype=dtype, value=value)\n",
    "            parsed_example[key] = NumpyFunctionHelper.tf_pad_str_sequences(h, tf.sparse.to_dense(parsed_example[key]))\n",
    "            parsed_example[key].set_shape([config['max_len']])\n",
    "    parsed_example['cp_media_level'] = tf.strings.as_string(parsed_example['cp_media_level'])\n",
    "    parsed_example['u_level'] = tf.strings.as_string(parsed_example['u_level'])\n",
    "    target = parsed_example['action']\n",
    "    del parsed_example['action']\n",
    "    return parsed_example, target\n",
    "                \n",
    "train_dataset = train.map(parse_function)\n",
    "test_dataset = test.map(parse_function)\n",
    "\n",
    "new_dataset = train_dataset\n",
    "new_dataset = new_dataset.batch(2)\n",
    "example_batch = next(iter(new_dataset))[0]\n",
    "\n",
    "# # feature_column.categorical_column_with_vocabulary_list(key='u_level', vocabulary_list=u_levels, num_oov_buckets=1)\n",
    "for feature_batch, label_batch in new_dataset.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "#     print('A batch of u_uli:', feature_batch['u_uli'])\n",
    "    print('A batch of request_id:', feature_batch['request_id'])\n",
    "#     print('A batch of item_id:', feature_batch['u_uli'])\n",
    "    print('A batch of u_uli_interest_weight:', feature_batch['u_uli_interest_weight'])\n",
    "    print('A batch of targets:', label_batch )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建特征列\n",
    "feature_columns = []\n",
    "feature_layer_inputs = {}\n",
    "real = {\n",
    "    colname : tf.feature_column.numeric_column(colname) \n",
    "          for colname in \n",
    "            ('rs_gactr,rs_p1_score,cp_is_local_publisher,cp_is_local,cp_vulgar_type,cp_clickbait_type' +\n",
    "             ',cp_word_count,cp_newsy_score,cp_life_hour').split(',')\n",
    "}\n",
    "sparse = {\n",
    "    't_channel': tf.feature_column.categorical_column_with_vocabulary_list('t_channel', vocabulary_list=channels),\n",
    "    'uid'   : tf.feature_column.categorical_column_with_hash_bucket('uid', hash_bucket_size=300000),\n",
    "    'u_level' : tf.feature_column.categorical_column_with_vocabulary_list('u_level', vocabulary_list=u_levels),\n",
    "    'item_id'   : tf.feature_column.categorical_column_with_hash_bucket('item_id', hash_bucket_size=300000),\n",
    "    'cp_publisher': tf.feature_column.categorical_column_with_vocabulary_list('cp_publisher', vocabulary_list=publishers),\n",
    "    'cp_media_level' : tf.feature_column.categorical_column_with_vocabulary_list('cp_media_level', vocabulary_list=media_levels),\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "    colname : tf.keras.layers.Input(name=colname, shape=(1,), dtype='float32') \n",
    "          for colname in real.keys()\n",
    "}\n",
    "inputs.update({\n",
    "    colname : tf.keras.layers.Input(name=colname, shape=(1,), dtype='string') \n",
    "          for colname in sparse.keys()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publishers 32413 channels 17 u_level 10 media_levels 10\n"
     ]
    }
   ],
   "source": [
    "print(\"publishers\", len(publishers), \"channels\",len(channels), 'u_level', len(u_levels), 'media_levels', len(media_levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimen(col):\n",
    "    if col == 'uid':\n",
    "        return 20\n",
    "    elif col == 'item_id':\n",
    "        return 20\n",
    "    elif col == 'cp_publisher':\n",
    "        return 20\n",
    "    elif key in ['u_uli_interest','u_umi_interest', 'u_usi_interest', 'cp_interests', 'rs_tag_interest']:\n",
    "        return 16\n",
    "    elif key in ['u_uli_cate','u_umi_cate', 'u_usi_cate', 'cp_category', 'rs_tag_cate']:\n",
    "        return 5\n",
    "    elif key in ['t_location','cp_location']:\n",
    "        return 10\n",
    "    elif key in ['rs_channel']:\n",
    "        return 5\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(key):\n",
    "    if key in ['u_uli_interest','u_umi_interest', 'u_usi_interest', 'cp_interests', 'rs_tag_interest']:\n",
    "        return its\n",
    "    elif key in ['u_uli_cate','u_umi_cate', 'u_usi_cate', 'cp_category', 'rs_tag_cate']:\n",
    "        return cates\n",
    "    elif key in ['t_location','cp_location']:\n",
    "        return locs\n",
    "    elif key in ['rs_channel']:\n",
    "        return rschannles\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_location 3\n",
      "u_uli_interest 50\n",
      "u_uli_cate 10\n",
      "u_umi_interest 20\n",
      "u_umi_cate 10\n",
      "u_usi_interest 15\n",
      "u_usi_cate 5\n",
      "cp_category 3\n",
      "cp_interests 8\n",
      "cp_location 3\n",
      "rs_channel 16\n",
      "rs_tag_interest 8\n",
      "rs_tag_cate 3\n"
     ]
    }
   ],
   "source": [
    "for config in sparse_configs:\n",
    "    key = config['key']\n",
    "    maxlen = config['max_len']\n",
    "    if key.endswith('weight') or key.endswith('dactr'):\n",
    "        continue\n",
    "    print(key, maxlen)\n",
    "    sparse[key] = tf.feature_column.categorical_column_with_vocabulary_list(key, vocabulary_list=get_dict(key))\n",
    "    inputs[key] = tf.keras.Input(shape=(maxlen,), name=key, dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征工程\n",
    "embed = {\n",
    "       'embed_{}'.format(colname) : tf.feature_column.embedding_column(col, get_dimen(col))\n",
    "          for colname, col in sparse.items()\n",
    "}\n",
    "\n",
    "real.update(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = {\n",
    "    colname : tf.feature_column.indicator_column(col)\n",
    "          for colname, col in sparse.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_HIDDEN_UNITS = '32,16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib64/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/lib64/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/lib64/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "def wide_and_deep_classifier(inputs, linear_feature_columns, dnn_feature_columns, dnn_hidden_units):\n",
    "    deep = tf.keras.layers.DenseFeatures(dnn_feature_columns, name='deep_inputs')(inputs)\n",
    "    layers = [int(x) for x in dnn_hidden_units.split(',')]\n",
    "    for layerno, numnodes in enumerate(layers):\n",
    "        deep = tf.keras.layers.Dense(numnodes, activation='relu', name='dnn_{}'.format(layerno+1))(deep)        \n",
    "    wide = tf.keras.layers.DenseFeatures(linear_feature_columns, name='wide_inputs')(inputs)\n",
    "    both = tf.keras.layers.concatenate([deep, wide], name='both')\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='pred')(both)\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_crossentropy', 'accuracy', tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "    \n",
    "model = wide_and_deep_classifier(\n",
    "    inputs,\n",
    "    linear_feature_columns = sparse.values(),\n",
    "    dnn_feature_columns = real.values(),\n",
    "    dnn_hidden_units = DNN_HIDDEN_UNITS)\n",
    "tf.keras.utils.plot_model(model, 'wide_and_deep_model.png', show_shapes=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "cp_category (InputLayer)        [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_clickbait_type (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_interests (InputLayer)       [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_is_local (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_is_local_publisher (InputLay [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_life_hour (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_location (InputLayer)        [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_media_level (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_newsy_score (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_publisher (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_vulgar_type (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp_word_count (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rs_channel (InputLayer)         [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rs_gactr (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rs_p1_score (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rs_tag_cate (InputLayer)        [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rs_tag_interest (InputLayer)    [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "t_channel (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "t_location (InputLayer)         [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_level (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_uli_cate (InputLayer)         [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_uli_interest (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_umi_cate (InputLayer)         [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_umi_interest (InputLayer)     [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_usi_cate (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_usi_interest (InputLayer)     [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "uid (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "deep_inputs (DenseFeatures)     (None, 85)           3522536     cp_category[0][0]                \n",
      "                                                                 cp_clickbait_type[0][0]          \n",
      "                                                                 cp_interests[0][0]               \n",
      "                                                                 cp_is_local[0][0]                \n",
      "                                                                 cp_is_local_publisher[0][0]      \n",
      "                                                                 cp_life_hour[0][0]               \n",
      "                                                                 cp_location[0][0]                \n",
      "                                                                 cp_media_level[0][0]             \n",
      "                                                                 cp_newsy_score[0][0]             \n",
      "                                                                 cp_publisher[0][0]               \n",
      "                                                                 cp_vulgar_type[0][0]             \n",
      "                                                                 cp_word_count[0][0]              \n",
      "                                                                 item_id[0][0]                    \n",
      "                                                                 rs_channel[0][0]                 \n",
      "                                                                 rs_gactr[0][0]                   \n",
      "                                                                 rs_p1_score[0][0]                \n",
      "                                                                 rs_tag_cate[0][0]                \n",
      "                                                                 rs_tag_interest[0][0]            \n",
      "                                                                 t_channel[0][0]                  \n",
      "                                                                 t_location[0][0]                 \n",
      "                                                                 u_level[0][0]                    \n",
      "                                                                 u_uli_cate[0][0]                 \n",
      "                                                                 u_uli_interest[0][0]             \n",
      "                                                                 u_umi_cate[0][0]                 \n",
      "                                                                 u_umi_interest[0][0]             \n",
      "                                                                 u_usi_cate[0][0]                 \n",
      "                                                                 u_usi_interest[0][0]             \n",
      "                                                                 uid[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dnn_1 (Dense)                   (None, 32)           2752        deep_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dnn_2 (Dense)                   (None, 16)           528         dnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "wide_inputs (DenseFeatures)     (None, 880634)       0           cp_category[0][0]                \n",
      "                                                                 cp_clickbait_type[0][0]          \n",
      "                                                                 cp_interests[0][0]               \n",
      "                                                                 cp_is_local[0][0]                \n",
      "                                                                 cp_is_local_publisher[0][0]      \n",
      "                                                                 cp_life_hour[0][0]               \n",
      "                                                                 cp_location[0][0]                \n",
      "                                                                 cp_media_level[0][0]             \n",
      "                                                                 cp_newsy_score[0][0]             \n",
      "                                                                 cp_publisher[0][0]               \n",
      "                                                                 cp_vulgar_type[0][0]             \n",
      "                                                                 cp_word_count[0][0]              \n",
      "                                                                 item_id[0][0]                    \n",
      "                                                                 rs_channel[0][0]                 \n",
      "                                                                 rs_gactr[0][0]                   \n",
      "                                                                 rs_p1_score[0][0]                \n",
      "                                                                 rs_tag_cate[0][0]                \n",
      "                                                                 rs_tag_interest[0][0]            \n",
      "                                                                 t_channel[0][0]                  \n",
      "                                                                 t_location[0][0]                 \n",
      "                                                                 u_level[0][0]                    \n",
      "                                                                 u_uli_cate[0][0]                 \n",
      "                                                                 u_uli_interest[0][0]             \n",
      "                                                                 u_umi_cate[0][0]                 \n",
      "                                                                 u_umi_interest[0][0]             \n",
      "                                                                 u_usi_cate[0][0]                 \n",
      "                                                                 u_usi_interest[0][0]             \n",
      "                                                                 uid[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "both (Concatenate)              (None, 880650)       0           dnn_2[0][0]                      \n",
      "                                                                 wide_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 1)            880651      both[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 4,406,467\n",
      "Trainable params: 4,406,467\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 1000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "ftest_dataset = test_dataset.shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7709/7709 [==============================] - 3032s 393ms/step - loss: 0.2466 - binary_crossentropy: 0.2467 - accuracy: 0.8941 - auc: 0.9625 - val_loss: 1.6115 - val_binary_crossentropy: 1.6209 - val_accuracy: 0.6102 - val_auc: 0.5642\n",
      "Epoch 2/10\n",
      "2026/7709 [======>.......................] - ETA: 38:55 - loss: 0.0822 - binary_crossentropy: 0.0822 - accuracy: 0.9632 - auc: 0.9954WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,binary_crossentropy,accuracy,auc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bbf62fc8e0f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(ftrain_dataset,\n\u001b[1;32m      3\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mftest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           epochs=10, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=2)])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "model.fit(ftrain_dataset,\n",
    "          validation_data=ftest_dataset,\n",
    "          epochs=10, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncross feature result\n",
    "files = list_sort_files(dir)\n",
    "tmps = []\n",
    "size = 0\n",
    "for file in files:\n",
    "    size += 1\n",
    "    tmps.append(file)\n",
    "#     print('train model use data from ', file)\n",
    "    if size > 72:\n",
    "        train_by_batch(tmps)\n",
    "        tmps = []\n",
    "        size = 0\n",
    "if size > 0:\n",
    "    train_by_batch(tmps)\n",
    "    size = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
